{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, Response, request, jsonify\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from src.hand_tracker_nms import HandTrackerNMS\n",
    "import src.extra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, Response\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import base64\n",
    "from flask_cors import CORS\n",
    "from src.hand_tracker_nms import HandTrackerNMS\n",
    "import src.extra\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "PALM_MODEL_PATH = \"models/palm_detection_without_custom_op.tflite\"\n",
    "LANDMARK_MODEL_PATH = \"models/hand_landmark.tflite\"\n",
    "ANCHORS_PATH = \"models/anchors.csv\"\n",
    "\n",
    "connections = src.extra.connections\n",
    "int_to_char = src.extra.classes\n",
    "\n",
    "# Initialize the HandTrackerNMS with debugging\n",
    "try:\n",
    "    detector = HandTrackerNMS(\n",
    "        PALM_MODEL_PATH,\n",
    "        LANDMARK_MODEL_PATH,\n",
    "        ANCHORS_PATH,\n",
    "        box_shift=0.2,\n",
    "        box_enlarge=1.3\n",
    "    )\n",
    "    print(\"HandTrackerNMS initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing HandTrackerNMS: {e}\")\n",
    "\n",
    "try:\n",
    "    gesture_clf = joblib.load(r'models/gesture_clf.pkl')\n",
    "    print(\"Gesture classifier loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading gesture classifier: {e}\")\n",
    "\n",
    "def detect_gesture(frame):\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    points, bboxes, joints = detector(image)\n",
    "    detected_letter = \"\"\n",
    "    if points is not None:\n",
    "        src.extra.draw_points(points, frame)\n",
    "        pred_sign = src.extra.predict_sign(joints, gesture_clf, src.extra.classes)\n",
    "        detected_letter = pred_sign\n",
    "    return detected_letter, frame\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return jsonify({\"message\": \"Welcome to the Gesture Detection API!\"})\n",
    "@app.route('/detect_image', methods=['POST'])\n",
    "def detect_image():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file part\"})\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({\"error\": \"No selected file\"})\n",
    "    if file:\n",
    "        image = np.frombuffer(file.read(), np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        detected_letter, _ = detect_gesture(image)\n",
    "        _, buffer = cv2.imencode('.jpg', image)\n",
    "        processed_image = base64.b64encode(buffer).decode('utf-8')\n",
    "        return jsonify({\"detected_letter\": detected_letter, \"image\": processed_image})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=800)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, Response\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import base64\n",
    "from flask_cors import CORS\n",
    "from src.hand_tracker_nms import HandTrackerNMS\n",
    "import src.extra\n",
    "import threading\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "PALM_MODEL_PATH = \"models/palm_detection_without_custom_op.tflite\"\n",
    "LANDMARK_MODEL_PATH = \"models/hand_landmark.tflite\"\n",
    "ANCHORS_PATH = \"models/anchors.csv\"\n",
    "\n",
    "connections = src.extra.connections\n",
    "int_to_char = src.extra.classes\n",
    "\n",
    "# Initialize the HandTrackerNMS with debugging\n",
    "try:\n",
    "    detector = HandTrackerNMS(\n",
    "        PALM_MODEL_PATH,\n",
    "        LANDMARK_MODEL_PATH,\n",
    "        ANCHORS_PATH,\n",
    "        box_shift=0.2,\n",
    "        box_enlarge=1.3\n",
    "    )\n",
    "    print(\"HandTrackerNMS initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing HandTrackerNMS: {e}\")\n",
    "\n",
    "try:\n",
    "    gesture_clf = joblib.load(r'models/gesture_clf.pkl')\n",
    "    print(\"Gesture classifier loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading gesture classifier: {e}\")\n",
    "\n",
    "detected_letter = \"\"\n",
    "detected_letter_lock = threading.Lock()\n",
    "\n",
    "def detect_gesture(frame):\n",
    "    global detected_letter\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    points, bboxes, joints = detector(image)\n",
    "    if points is not None:\n",
    "        src.extra.draw_points(points, frame)\n",
    "        pred_sign = src.extra.predict_sign(joints, gesture_clf, src.extra.classes)\n",
    "        with detected_letter_lock:\n",
    "            detected_letter = pred_sign\n",
    "        # Overlay detected letter on frame\n",
    "        cv2.putText(frame, pred_sign, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    return frame\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return jsonify({\"message\": \"Welcome to the Gesture Detection API!\"})\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    def generate_frames():\n",
    "        capture = cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            hasFrame, frame = capture.read()\n",
    "            if not hasFrame:\n",
    "                break\n",
    "            processed_frame = detect_gesture(frame)\n",
    "            ret, buffer = cv2.imencode('.jpg', processed_frame)\n",
    "            frame = buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/get_detected_letter', methods=['GET'])\n",
    "def get_detected_letter():\n",
    "    global detected_letter\n",
    "    with detected_letter_lock:\n",
    "        return jsonify({\"detected_letter\": detected_letter})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, Response\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import base64\n",
    "from flask_cors import CORS\n",
    "from src.hand_tracker_nms import HandTrackerNMS\n",
    "import src.extra\n",
    "import threading\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "PALM_MODEL_PATH = \"models/palm_detection_without_custom_op.tflite\"\n",
    "LANDMARK_MODEL_PATH = \"models/hand_landmark.tflite\"\n",
    "ANCHORS_PATH = \"models/anchors.csv\"\n",
    "\n",
    "connections = src.extra.connections\n",
    "int_to_char = src.extra.classes\n",
    "\n",
    "# Initialize the HandTrackerNMS with debugging\n",
    "try:\n",
    "    detector = HandTrackerNMS(\n",
    "        PALM_MODEL_PATH,\n",
    "        LANDMARK_MODEL_PATH,\n",
    "        ANCHORS_PATH,\n",
    "        box_shift=0.2,\n",
    "        box_enlarge=1.3\n",
    "    )\n",
    "    print(\"HandTrackerNMS initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing HandTrackerNMS: {e}\")\n",
    "\n",
    "try:\n",
    "    gesture_clf = joblib.load(r'models/gesture_clf.pkl')\n",
    "    print(\"Gesture classifier loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading gesture classifier: {e}\")\n",
    "\n",
    "detected_letter = \"\"\n",
    "detected_letter_lock = threading.Lock()\n",
    "\n",
    "def detect_gesture(frame):\n",
    "    global detected_letter\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    points, bboxes, joints = detector(image)\n",
    "    if points is not None:\n",
    "        src.extra.draw_points(points, frame)\n",
    "        pred_sign = src.extra.predict_sign(joints, gesture_clf, src.extra.classes)\n",
    "        with detected_letter_lock:\n",
    "            detected_letter = pred_sign\n",
    "        # Overlay detected letter on frame\n",
    "        cv2.putText(frame, pred_sign, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    return frame\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return jsonify({\"message\": \"Welcome to the Gesture Detection API!\"})\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    def generate_frames():\n",
    "        capture = cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            hasFrame, frame = capture.read()\n",
    "            if not hasFrame:\n",
    "                break\n",
    "            processed_frame = detect_gesture(frame)\n",
    "            ret, buffer = cv2.imencode('.jpg', processed_frame)\n",
    "            frame = buffer.tobytes()\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/get_detected_letter', methods=['GET'])\n",
    "def get_detected_letter():\n",
    "    global detected_letter\n",
    "    with detected_letter_lock:\n",
    "        return jsonify({\"detected_letter\": detected_letter})\n",
    "\n",
    "@app.route('/detect_image', methods=['POST'])\n",
    "def detect_image():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file part\"})\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({\"error\": \"No selected file\"})\n",
    "    if file:\n",
    "        image = np.frombuffer(file.read(), np.uint8)\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        detect_gesture(image)  # Update the image in place\n",
    "        with detected_letter_lock:\n",
    "            detected_letter_local = detected_letter  # Fetch the letter detected during image processing\n",
    "        _, buffer = cv2.imencode('.jpg', image)\n",
    "        processed_image = base64.b64encode(buffer).decode('utf-8')\n",
    "        return jsonify({\"detected_letter\": detected_letter_local, \"image\": processed_image})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=700)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
